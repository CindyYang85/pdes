# FileName: parallel.config 

# Purpose : This is a configuration file that the simulation kernel
#           requires for configuring the different components in the 
#           simulation kernel.

# Notes   : Empty lines are ignored; a comment is indicated by a "#".

# Do you want debugging information to be shown
# Note: You will have to build with the -DDEVELOPER_ASSERTIONS flag turned
#       on before you can use this option.
# Choices:
# [a] True or False
#Debug : true #This dosent seem to work, build flag does not exist  

ParallelDebug {
	#Put every CPU into a loop that could only break out in gdb.  
	#To Use: set true and
	#Kick off a simulation, all sim managers will be sitting there spinning,
	#Attach on every CPU with gdb, and then break them out and you could watch
	#every CPU in gdb simultaneously. Use: "set x=0" in gdb to break the while loop
 	SpinBeforeSimulationStart : False
}

# Simulation Options:
# 	TimeWarp, 	 (Single thread TimeWarp simulation)
#	ThreadedWarp (TimeWarp with multiple threads executing objects)
#	Sequential	 (Single thread sequential simulation)
Simulation : TimeWarp
#Simulation: Sequential

#TimeWarp Scope
TimeWarp {
  ###
  # ObjectQueue and ThreadControl are only used for ThreadedWarp Simulation types
  ###
  # ObjectQueue:
  # Type Options:
  #    	CalendarQueue (Not Currently Working)
  # 	LockedQueue
  # NumberOfBuckets : For CalendarQueue specify an integer number of buckets
  # BucketWidth : For CalendarQueue specify an integer width for each bucket
  ObjectQueue {
    Type : LockedQueue
    NumberOfBuckets : 5
    BucketWidth : 2
  }
  # ThreadControl:
  # WorkerThreadCount : Integer value for the number of worker threads
  #						If left undefined /proc/cpuinfo is used
  ThreadControl {
    WorkerThreadCount : 1
  }
  
  # Type Options:
  # 	Default, MultiSet (must use if using MultiSet event list)
  Scheduler {
    Type : MultiSet
  }
  
  # EventList:
  # Type Options:
  # 	Default, MultiSet, Threaded
  EventList {
    Type : MultiSet
  }

  # CommunicationManager:
  # PhysicalLayer Options:
  # 	MPI 		requires (--enable-timewarp)
  # 	TCPSelect  	requires (--enable-timewarp)
  # 	UDPSelect  	requires (--enable-timewarp), not implemented yet
  # Type Options:
  # 	Default
  # 	MessageAggregating - Not fully implemented yet.
  # Nodes Format:
  # 	List of nodes to simulate on IN ADDITION TO the starting node
  # 	At least one node besides the current must be specified or
  #		do not specify the Nodes option to run 1 simulation manager
  # 	The names can be repeated however for threadedwarp
  #		it would be more efficent to increase the number of threads
  CommunicationManager { 
    PhysicalLayer: MPI
    #PhysicalLayer: TCPSelect  
    Type : Default
    Nodes : localhost, localhost, localhost
  }
	
  # StateManager:
  # Type Options:
  #	Periodic, Adaptive
  # Period Format:
  # 	Must be an integer value
  StateManager {
    Type: Periodic
    Period : 10
  }

  # OutputManager:
  # Type Options:
  # 	Lazy, Dynamic, Aggressive 
  # AntiMessages Options: 
  # 	Default
  #	One
  OutputManager {
    Type : Aggressive
    AntiMessages: Default
  }

  # GVTManager
  # Type Options:
  # 	Mattern, AtomicMattern
  # Period format:
  # 	Must be an integer value
  GVTManager {
    Type : Mattern
    Period : 1000
  }

  # Optimistic Fossil Collection Manager
  # Type Options:
  #     None, Cheby
  OptFossilCollManager {
    Type : None
    CheckpointTime : 1000
    MinimumSamples : 64
    MaximumSamples : 100
    DefaultLength : 2000
    AcceptableRisk : 0.99
  }

  # Clock Frequency Manager
  # Type Options:
  #     Centralized, Distributed, None
  # Period:
  #     integer format
  # NumCPUs:
  #     integer format
  ClockFrequencyManager {
    #Type: Centralized
    Dummy: True
    Type: Distributed
    #Type: None
    FIRSize: 4
    Period: 5000
    NumCPUs: 4
  }
}
